{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from movingpose.estimator import neighbors\n",
    "from movingpose.estimator import classifiers\n",
    "\n",
    "from movingpose.preprocessing import moving_pose\n",
    "from movingpose.preprocessing import kinect_skeleton_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle multiview action data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"../pickle/multiview.p\"):\n",
    "    kinect_skeleton_data.pickle_dir(\"../pickle/multiview.p\", \"../ext/dataset/multiview_action/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_uuid (press `enter` to create a new model):c7f7094d\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "cur_uuid = str(input(\"cur_uuid (press `enter` to create a new model):\"))\n",
    "dir_path = f\"../pickle/{cur_uuid}\"\n",
    "\n",
    "if not (cur_uuid != \"\" and os.path.isdir(dir_path)):\n",
    "    print(\"Creating data...\")\n",
    "\n",
    "    # Load pickled multiview action data\n",
    "    raw_data_dict = kinect_skeleton_data.load_pickle(\"../pickle/multiview.p\")\n",
    "\n",
    "    X, labels = moving_pose.format_skeleton_data_dict(raw_data_dict)\n",
    "\n",
    "    # Verify shape is correct\n",
    "    for action in X:\n",
    "        for frame_num, pose in enumerate(action):\n",
    "            assert pose.shape == (20, 10), f\"{pose.shape} =/= (20, 10)\"\n",
    "            for i, descriptor in enumerate(pose):\n",
    "                if i == 0:\n",
    "                    assert list(descriptor)[:-1] == [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                assert descriptor[-1] == frame_num, f\"{descriptor[-1]} =/= {frame_num}\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, random_state=42)\n",
    "\n",
    "    cur_uuid = str(uuid.uuid4())[0:8]\n",
    "    dir_path = f\"../pickle/{cur_uuid}\"\n",
    "\n",
    "    training_data = {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    os.mkdir(dir_path)\n",
    "    with open(f'../pickle/{cur_uuid}/train_test_splits.p', 'wb') as file:\n",
    "        pickle.dump(training_data, file)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "with open(dir_path + \"/train_test_splits.p\", 'rb') as fp:\n",
    "    training_data = pickle.load(fp)\n",
    "\n",
    "X_train, X_test = training_data[\"X_train\"], training_data[\"X_test\"]\n",
    "y_train, y_test = training_data[\"y_train\"], training_data[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pickle Action Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pickle_action_classifiers(n_training_neighbors, cache_path):\n",
    "    nearest_pose_estimator = neighbors.NearestPoses(\n",
    "        n_neighbors=20,\n",
    "        n_training_neighbors=n_training_neighbors,\n",
    "        alpha=0.75,\n",
    "        beta=0.6,\n",
    "        kappa=80\n",
    "    )\n",
    "    action_classifier = classifiers.ActionClassifier(\n",
    "        nearest_pose_estimator=nearest_pose_estimator,\n",
    "        theta=0.5,\n",
    "        n=80\n",
    "    )\n",
    "    action_classifier.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cache_path=cache_path,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "cache_workers = []\n",
    "for n_training_neighbors in [2000, 5000, 20000]:\n",
    "    cache_path = f\"../pickle/{cur_uuid}/action_classifier_cache-{str(n_training_neighbors)}.p\"\n",
    "    if not os.path.exists(cache_path):\n",
    "        worker = multiprocessing.Process(\n",
    "            target=\n",
    "                pickle_action_classifiers,\n",
    "            args=(\n",
    "                n_training_neighbors,\n",
    "                cache_path\n",
    "            )\n",
    "        )\n",
    "        cache_workers.append(worker)\n",
    "\n",
    "for cache_worker in cache_workers:\n",
    "    cache_worker.start()\n",
    "    \n",
    "for cache_worker in cache_workers:\n",
    "    cache_worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Action Classifier with normalized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of CPU cores this computer has (ex. '12'): 8\n",
      "Predicted 0.0%\n",
      "Predicted 12.5%\n",
      "Predicted 25.0%\n",
      "Predicted 37.5%\n",
      "Predicted 50.0%\n"
     ]
    }
   ],
   "source": [
    "def score(n_neighbors, n_training_neighbors, alpha, beta, kappa, theta, n):\n",
    "    nearest_pose_estimator = neighbors.NearestPoses(\n",
    "        n_neighbors=n_neighbors,\n",
    "        n_training_neighbors=n_training_neighbors,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        kappa=kappa\n",
    "    )\n",
    "    action_classifier = classifiers.ActionClassifier(\n",
    "        nearest_pose_estimator=nearest_pose_estimator,\n",
    "        theta=theta,\n",
    "        n=n\n",
    "    )\n",
    "    action_classifier.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cache_path=f\"../pickle/{cur_uuid}/action_classifier_cache-{str(n_training_neighbors)}.p\"\n",
    "    )\n",
    "\n",
    "    pred_start_time = time.time()\n",
    "    y_pred = action_classifier.predict_all(X_test, verbose=True)\n",
    "    total_time = time.time() - pred_start_time\n",
    "    total_mins = total_time/60\n",
    "\n",
    "    result = 0\n",
    "    for pred, actual in zip(y_pred, y_test):\n",
    "        result += 1 if pred == actual else 0\n",
    "    print(f\"Predicted {result}/{len(y_pred)}\")\n",
    "\n",
    "    prediction_info = {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"prediction_speed\": total_mins,\n",
    "        \"action_classifier_name\": str(action_classifier),\n",
    "        \"action_classifier_params\": action_classifier.get_params()\n",
    "    }\n",
    "\n",
    "    with open(f'../pickle/{cur_uuid}/prediction-[{action_classifier}].p', 'wb') as file:\n",
    "        pickle.dump(prediction_info, file)\n",
    "\n",
    "workers = []\n",
    "for kappa in [100]:\n",
    "    for n in [100]:\n",
    "        for theta in [0.7]:\n",
    "            for n_neighbors in [100]:\n",
    "                for n_training_neighbors in [20000]:\n",
    "                    for alpha in [0.75]:\n",
    "                        for beta in [0.6]:\n",
    "                            worker = multiprocessing.Process(\n",
    "                                target=\n",
    "                                    score,\n",
    "                                args=(\n",
    "                                    n_neighbors,\n",
    "                                    n_training_neighbors,\n",
    "                                    alpha,\n",
    "                                    beta,\n",
    "                                    kappa,\n",
    "                                    theta,\n",
    "                                    n\n",
    "                                )\n",
    "                            )\n",
    "                            workers.append(worker)\n",
    "\n",
    "num_cpu_cores = os.getenv(\"NUM_CPU_CORES\")\n",
    "if num_cpu_cores is None:\n",
    "    num_cpu_cores = input(\"Enter the number of CPU cores this computer has (ex. '12'): \")\n",
    "num_cpu_cores = max(1, int(num_cpu_cores) - 4)\n",
    "\n",
    "num_workers_executed = num_cpu_cores\n",
    "while num_workers_executed - num_cpu_cores < len(workers):\n",
    "    for i in range(num_cpu_cores, max(num_workers_executed - len(workers), 0), -1):\n",
    "        workers[num_workers_executed - i].start()\n",
    "    for i in range(num_cpu_cores, max(num_workers_executed - len(workers), 0), -1):\n",
    "        workers[num_workers_executed - i].join()\n",
    "    num_workers_executed += num_cpu_cores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
