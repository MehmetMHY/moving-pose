{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Run ACTION_RECOGNITION.ipynb before running model_analysis.ipynb #####"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from movingpose.estimator import classifiers\n",
    "from movingpose.estimator import neighbors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-4c83b816c6bc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbeta\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'beta' is not defined"
     ]
    }
   ],
   "source": [
    "# Strength of precision vs recall\n",
    "beta = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load model data and generate metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_uuid = str(input(\"cur_uuid:\"))\n",
    "dir_path = f\"../pickle/{cur_uuid}\"\n",
    "\n",
    "if not (cur_uuid != \"\" and os.path.isdir(dir_path)):\n",
    "    print(\"ERROR :: UUID not found\")\n",
    "    print(\"Please enter the correct UUID or run action_recognition.ipynb and pass in the associated UUID\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "with open(dir_path + \"/train_test_splits.p\", 'rb') as fp:\n",
    "    training_data = pickle.load(fp)\n",
    "\n",
    "X_train, X_test = training_data[\"X_train\"], training_data[\"X_test\"]\n",
    "y_train, y_test = training_data[\"y_train\"], training_data[\"y_test\"]\n",
    "\n",
    "all_predictions_fns = [file_name for file_name in os.listdir(dir_path) if file_name.startswith(\"prediction\")]\n",
    "\n",
    "# results_dict[str(action_classifier)] = {\n",
    "#   \"y_pred\": y_pred,\n",
    "#   \"action_classifier_params\": action_classifier_params,\n",
    "#   \"confusion_matrix\": confusion_matrix,\n",
    "#   \"precision\": precision,\n",
    "#   \"recall\": recall,\n",
    "#   \"fbetascore\": fscore,\n",
    "#   \"support\": support,\n",
    "#   \"accuracy\": accuracy,\n",
    "#   \"prediction_speed\": prediction_speed\n",
    "# }\n",
    "predictions_dict = {}\n",
    "\n",
    "for prediction_fn in all_predictions_fns:\n",
    "    with open(f\"{dir_path}/{prediction_fn}.p\", 'rb') as fp:\n",
    "        prediction_info = pickle.load(fp)\n",
    "\n",
    "        action_classifier_name = prediction_info[\"action_classifier_name\"]\n",
    "        y_pred = prediction_info[\"y_pred\"]\n",
    "        action_classifier_params = prediction_info[\"action_classifier_params\"]\n",
    "        prediction_speed = prediction_info[\"prediction_speed\"]\n",
    "\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "        precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, y_pred, beta=beta)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        predictions_dict[action_classifier_name] = {\n",
    "            \"y_pred\": y_pred,\n",
    "            \"action_classifier_params\": action_classifier_params,\n",
    "            \"confusion_matrix\": confusion_matrix,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"fbetascore\": fscore,\n",
    "            \"support\": support,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"prediction_speed\": prediction_speed\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Organize hyper parameter combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hpc_values[hpc_name] = set(hpc_value, ... (all hpc_values))\n",
    "hpc_values_dict = collections.defaultdict(set)\n",
    "\n",
    "for model_name, prediction_info in predictions_dict.items():\n",
    "    action_classifier = prediction_info[\"action_classifier_params\"]\n",
    "    pose_estimator = action_classifier[\"nearest_pose_estimator\"]\n",
    "\n",
    "    hpcs = {\n",
    "        \"theta\": action_classifier[\"theta\"],\n",
    "        \"n\": action_classifier[\"n\"],\n",
    "        \"alpha\": pose_estimator[\"alpha\"],\n",
    "        \"beta\": pose_estimator[\"beta\"],\n",
    "        \"kappa\": pose_estimator[\"kappa\"],\n",
    "        \"n_neighbors\": pose_estimator[\"n_neighbors\"],\n",
    "        \"n_training_neighbors\": pose_estimator[\"n_training_neighbors\"]\n",
    "    }\n",
    "\n",
    "    for hpc_name, hpc_value in hpcs.items():\n",
    "        hpc_values_dict[hpc_name].add(hpc_value)\n",
    "\n",
    "# hpc_combinations[hpc_name] = set(\"str(action_recognition) with wildcard for hpc_value\", ... (all hpc name templates))\n",
    "hpc_combinations = collections.defaultdict(set)\n",
    "for hpc_name in hpc_values_dict.keys():\n",
    "    for theta in hpc_values_dict[\"theta\"]:\n",
    "        for n in hpc_values_dict[\"n\"]:\n",
    "            for alpha in hpc_values_dict[\"alpha\"]:\n",
    "                for beta in hpc_values_dict[\"beta\"]:\n",
    "                    for kappa in hpc_values_dict[\"kappa\"]:\n",
    "                        for n_neighbors in hpc_values_dict[\"n_neighbors\"]:\n",
    "                            for n_training_neighbors in hpc_values_dict[\"n_training_neighbors\"]:\n",
    "                                nearest_pose_estimator = neighbors.NearestPoses(\n",
    "                                    n_neighbors=n_neighbors,\n",
    "                                    n_training_neighbors=n_training_neighbors,\n",
    "                                    alpha=alpha,\n",
    "                                    beta=beta,\n",
    "                                    kappa=kappa\n",
    "                                )\n",
    "                                action_classifier = classifiers.ActionClassifier(\n",
    "                                    nearest_pose_estimator=nearest_pose_estimator,\n",
    "                                    theta=theta,\n",
    "                                    n=n\n",
    "                                )\n",
    "                                model_name = str(action_classifier)\n",
    "                                model_name_parts = model_name.split(\"=\")\n",
    "                                for i, model_name_part in enumerate(model_name_parts):\n",
    "                                    if not model_name_part.ends_with(hpc_name):\n",
    "                                        continue\n",
    "                                    model_name_parts[i+1] = \"%d\"\n",
    "                                    break\n",
    "                                template_name = \"=\".join(model_name_parts)\n",
    "                                hpc_combinations[hpc_name].add(template_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Assert all required prediction files exist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for hpc_name, model_name_templates in hpc_combinations.items():\n",
    "    for hpc_value in hpc_values_dict.values():\n",
    "        for model_name_template in model_name_templates:\n",
    "            assert (os.path.isfile(f\"{dir_path}/{model_name_template % hpc_value}.p\"),\n",
    "                        f\"{dir_path}/{model_name_template % hpc_value}.p file does not exist\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualize hyperparameter combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    {\n",
    "        \"id\": \"prediction_speed\",\n",
    "        \"name\": \"Time to Predict 80 Actions (min)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"accuracy\",\n",
    "        \"name\": \"Accuracy (%)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"fbetascore\",\n",
    "        \"name\": f\"F{beta}-Score (%)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"precision\",\n",
    "        \"name\": \"Precision (%)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"recall\",\n",
    "        \"name\": \"Recall (%)\"\n",
    "    }\n",
    "]\n",
    "hpc_names = list(hpc_values_dict.copy())\n",
    "\n",
    "plots = collections.defaultdict(list)\n",
    "for hpc_name, model_name_templates in hpc_combinations.items():\n",
    "    for hpc_num, hpc_value in enumerate(hpc_values_dict.values()):\n",
    "        for model_name_template in model_name_templates:\n",
    "            prediction_info = predictions_dict[model_name_template % hpc_value]\n",
    "            for metric_num, metric_info in enumerate(metrics):\n",
    "                plots[(hpc_num, metric_num)].append((hpc_value, prediction_info[metric_info[\"id\"]]))\n",
    "\n",
    "fig, axs = plt.subplots(len(hpc_values_dict.values()), 5)\n",
    "for (col, row), plot in plots.items():\n",
    "    for (x, y) in plot:\n",
    "        axs[col, row].scatter(x, y)\n",
    "    xlabel = f\"{hpc_names[col].title()} Values\"\n",
    "    ylabel = metrics[row][\"name\"]\n",
    "    axs[col, row].set(xlabel=xlabel, ylabel=ylabel)\n",
    "    axs[col, row].set_title(\"Change in {ylabel} as {xlabel} Change\")\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}